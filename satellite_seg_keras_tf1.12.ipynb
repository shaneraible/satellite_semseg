{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"satellite_seg_keras_tf1.12.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1PyfdqRPCY-gtw3z80ZZWXuMhd1q535Qo","authorship_tag":"ABX9TyP3dwyarThQKoivaY4sz3OD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"uvJPws1ReSxF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1594874221345,"user_tz":240,"elapsed":1607,"user":{"displayName":"SHane Raible","photoUrl":"","userId":"13629952602245877407"}},"outputId":"a069ddbe-3951-45ca-e910-fdefdd4f7ddb"},"source":["import tensorflow as tf\n","import tifffile as tiff"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"3KBnd3w-j2tA","colab_type":"text"},"source":["All imports"]},{"cell_type":"code","metadata":{"id":"X-q3tG-Aekr6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594874221345,"user_tz":240,"elapsed":1598,"user":{"displayName":"SHane Raible","photoUrl":"","userId":"13629952602245877407"}},"outputId":"8bf9aa30-0264-4678-fc57-c1d7cfaee507"},"source":["from keras.models import Model\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout\n","from keras.optimizers import Adam\n","from keras.utils import plot_model\n","from keras import backend as K\n","import os.path\n","import numpy as np\n","import tifffile as tiff\n","from keras.callbacks import CSVLogger\n","from keras.callbacks import TensorBoard\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","import random\n","import sys"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zUcUlhya2dg0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594874221346,"user_tz":240,"elapsed":1591,"user":{"displayName":"SHane Raible","photoUrl":"","userId":"13629952602245877407"}}},"source":["# !pip install tensorflow==1.12.0\n","# !pip install keras==2.2.4"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"QIZqwlMigpIf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594874221347,"user_tz":240,"elapsed":1585,"user":{"displayName":"SHane Raible","photoUrl":"","userId":"13629952602245877407"}}},"source":["assert(tf.__version__==\"1.12.0\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_jx0wUh0naz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594874221347,"user_tz":240,"elapsed":1581,"user":{"displayName":"SHane Raible","photoUrl":"","userId":"13629952602245877407"}}},"source":[""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ukfU64TNgktX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594874221348,"user_tz":240,"elapsed":1578,"user":{"displayName":"SHane Raible","photoUrl":"","userId":"13629952602245877407"}}},"source":["sys.path.insert(1, '/content/drive/My Drive/Colab Notebooks/deep-unet-for-satellite-image-segmentation-master')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_xQrH_UTj57A","colab_type":"text"},"source":["Getting a patch of a given image"]},{"cell_type":"code","metadata":{"id":"nHasjFU8gItf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594874221349,"user_tz":240,"elapsed":1576,"user":{"displayName":"SHane Raible","photoUrl":"","userId":"13629952602245877407"}}},"source":["def get_rand_patch(img, mask, sz=160):\n","    \"\"\"\n","    :param img: ndarray with shape (x_sz, y_sz, num_channels)\n","    :param mask: binary ndarray with shape (x_sz, y_sz, num_classes)\n","    :param sz: size of random patch\n","    :return: patch with shape (sz, sz, num_channels)\n","    \"\"\"\n","    assert len(img.shape) == 3 and img.shape[0] > sz and img.shape[1] > sz and img.shape[0:2] == mask.shape[0:2]\n","    xc = random.randint(0, img.shape[0] - sz)\n","    yc = random.randint(0, img.shape[1] - sz)\n","    patch_img = img[xc:(xc + sz), yc:(yc + sz)]\n","    patch_mask = mask[xc:(xc + sz), yc:(yc + sz)]\n","\n","    # Apply some random transformations\n","    random_transformation = np.random.randint(1,8)\n","    if random_transformation == 1:  # reverse first dimension\n","        patch_img = patch_img[::-1,:,:]\n","        patch_mask = patch_mask[::-1,:,:]\n","    elif random_transformation == 2:    # reverse second dimension\n","        patch_img = patch_img[:,::-1,:]\n","        patch_mask = patch_mask[:,::-1,:]\n","    elif random_transformation == 3:    # transpose(interchange) first and second dimensions\n","        patch_img = patch_img.transpose([1,0,2])\n","        patch_mask = patch_mask.transpose([1,0,2])\n","    elif random_transformation == 4:\n","        patch_img = np.rot90(patch_img, 1)\n","        patch_mask = np.rot90(patch_mask, 1)\n","    elif random_transformation == 5:\n","        patch_img = np.rot90(patch_img, 2)\n","        patch_mask = np.rot90(patch_mask, 2)\n","    elif random_transformation == 6:\n","        patch_img = np.rot90(patch_img, 3)\n","        patch_mask = np.rot90(patch_mask, 3)\n","    else:\n","        pass\n","\n","    return patch_img, patch_mask\n","\n","\n","def get_patches(x_dict, y_dict, n_patches, sz=160):\n","    x = list()\n","    y = list()\n","    total_patches = 0\n","    while total_patches < n_patches:\n","        img_id = random.sample(x_dict.keys(), 1)[0]\n","        img = x_dict[img_id]\n","        mask = y_dict[img_id]\n","        img_patch, mask_patch = get_rand_patch(img, mask, sz)\n","        x.append(img_patch)\n","        y.append(mask_patch)\n","        total_patches += 1\n","    print('Generated {} patches'.format(total_patches))\n","    return np.array(x), np.array(y)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z0hy7YkwkCC4","colab_type":"text"},"source":["The UNET model"]},{"cell_type":"code","metadata":{"id":"tREtBHBDeMoo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594874221538,"user_tz":240,"elapsed":1762,"user":{"displayName":"SHane Raible","photoUrl":"","userId":"13629952602245877407"}}},"source":["def unet_model(n_classes=5, im_sz=160, n_channels=8, n_filters_start=32, growth_factor=2, upconv=True,\n","               class_weights=[0.2, 0.3, 0.1, 0.1, 0.3]):\n","    droprate=0.25\n","    n_filters = n_filters_start\n","    inputs = Input((im_sz, im_sz, n_channels))\n","    #inputs = BatchNormalization()(inputs)\n","    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n","    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    #pool1 = Dropout(droprate)(pool1)\n","\n","    n_filters *= growth_factor\n","    pool1 = BatchNormalization()(pool1)\n","    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    pool2 = Dropout(droprate)(pool2)\n","\n","    n_filters *= growth_factor\n","    pool2 = BatchNormalization()(pool2)\n","    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    pool3 = Dropout(droprate)(pool3)\n","\n","    n_filters *= growth_factor\n","    pool3 = BatchNormalization()(pool3)\n","    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)\n","    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_0)\n","    pool4_1 = MaxPooling2D(pool_size=(2, 2))(conv4_0)\n","    pool4_1 = Dropout(droprate)(pool4_1)\n","\n","    n_filters *= growth_factor\n","    pool4_1 = BatchNormalization()(pool4_1)\n","    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_1)\n","    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_1)\n","    pool4_2 = MaxPooling2D(pool_size=(2, 2))(conv4_1)\n","    pool4_2 = Dropout(droprate)(pool4_2)\n","\n","    n_filters *= growth_factor\n","    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_2)\n","    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)\n","\n","    n_filters //= growth_factor\n","    if upconv:\n","        up6_1 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4_1])\n","    else:\n","        up6_1 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4_1])\n","    up6_1 = BatchNormalization()(up6_1)\n","    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_1)\n","    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_1)\n","    conv6_1 = Dropout(droprate)(conv6_1)\n","\n","    n_filters //= growth_factor\n","    if upconv:\n","        up6_2 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_1), conv4_0])\n","    else:\n","        up6_2 = concatenate([UpSampling2D(size=(2, 2))(conv6_1), conv4_0])\n","    up6_2 = BatchNormalization()(up6_2)\n","    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_2)\n","    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_2)\n","    conv6_2 = Dropout(droprate)(conv6_2)\n","\n","    n_filters //= growth_factor\n","    if upconv:\n","        up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_2), conv3])\n","    else:\n","        up7 = concatenate([UpSampling2D(size=(2, 2))(conv6_2), conv3])\n","    up7 = BatchNormalization()(up7)\n","    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)\n","    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)\n","    conv7 = Dropout(droprate)(conv7)\n","\n","    n_filters //= growth_factor\n","    if upconv:\n","        up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n","    else:\n","        up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])\n","    up8 = BatchNormalization()(up8)\n","    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)\n","    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)\n","    conv8 = Dropout(droprate)(conv8)\n","\n","    n_filters //= growth_factor\n","    if upconv:\n","        up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n","    else:\n","        up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])\n","    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)\n","    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)\n","\n","    conv10 = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)\n","\n","    model = Model(inputs=inputs, outputs=conv10)\n","\n","    def weighted_binary_crossentropy(y_true, y_pred):\n","        class_loglosses = K.mean(K.binary_crossentropy(y_true, y_pred), axis=[0, 1, 2])\n","        return K.sum(class_loglosses * K.constant(class_weights))\n","\n","    model.compile(optimizer=Adam(), loss=weighted_binary_crossentropy)\n","    return model\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y9frQMFbkHuo","colab_type":"text"},"source":["Training methods"]},{"cell_type":"code","metadata":{"id":"UnHi7RRAfubo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":544},"outputId":"113b775e-49eb-49ce-cc93-e71ff8b8db1a"},"source":["def normalize(img):\n","    min = img.min()\n","    max = img.max()\n","    x = 2.0 * (img - min) / (max - min) - 1.0\n","    return x\n","\n","\n","\n","N_BANDS = 8\n","N_CLASSES = 5  # buildings, roads, trees, crops and water\n","CLASS_WEIGHTS = [0.2, 0.3, 0.1, 0.1, 0.3]\n","N_EPOCHS = 150\n","UPCONV = True\n","PATCH_SZ = 64   # should divide by 16\n","BATCH_SIZE = 100\n","TRAIN_SZ = 4000  # train size\n","VAL_SZ = 1000    # validation size\n","\n","\n","def get_model():\n","    return unet_model(N_CLASSES, PATCH_SZ, n_channels=N_BANDS, upconv=UPCONV, class_weights=CLASS_WEIGHTS)\n","\n","weights_path = '/content/drive/My Drive/Colab Notebooks/satelliteimage_segmentation/weights'\n","if not os.path.exists(weights_path):\n","    os.makedirs(weights_path)\n","weights_path += '/unet_weights.hdf5'\n","\n","trainIds = [str(i).zfill(2) for i in range(1, 25)]  # all availiable ids: from \"01\" to \"24\"\n","\n","\n","if __name__ == '__main__':\n","    X_DICT_TRAIN = dict()\n","    Y_DICT_TRAIN = dict()\n","    X_DICT_VALIDATION = dict()\n","    Y_DICT_VALIDATION = dict()\n","\n","    print('Reading images')\n","    for img_id in trainIds:\n","        img_m = normalize(tiff.imread('/content/drive/My Drive/Colab Notebooks/satelliteimage_segmentation/data/mband/{}.tif'.format(img_id)).transpose([1, 2, 0]))\n","        mask = tiff.imread('/content/drive/My Drive/Colab Notebooks/satelliteimage_segmentation/data/gt_mband/{}.tif'.format(img_id)).transpose([1, 2, 0]) / 255\n","        train_xsz = int(3/4 * img_m.shape[0])  # use 75% of image as train and 25% for validation\n","        X_DICT_TRAIN[img_id] = img_m[:train_xsz, :, :]\n","        Y_DICT_TRAIN[img_id] = mask[:train_xsz, :, :]\n","        X_DICT_VALIDATION[img_id] = img_m[train_xsz:, :, :]\n","        Y_DICT_VALIDATION[img_id] = mask[train_xsz:, :, :]\n","        print(img_id + ' read')\n","    print('Images were read')\n","\n","    def train_net():\n","        print(\"start train net\")\n","        x_train, y_train = get_patches(X_DICT_TRAIN, Y_DICT_TRAIN, n_patches=TRAIN_SZ, sz=PATCH_SZ)\n","        x_val, y_val = get_patches(X_DICT_VALIDATION, Y_DICT_VALIDATION, n_patches=VAL_SZ, sz=PATCH_SZ)\n","        model = get_model()\n","        if os.path.isfile(weights_path):\n","            model.load_weights(weights_path)\n","        #model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_weights_only=True, save_best_only=True)\n","        #early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n","        #reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, min_lr=0.00001)\n","        model_checkpoint = ModelCheckpoint(weights_path, monitor='val_loss', save_best_only=True)\n","        csv_logger = CSVLogger('log_unet.csv', append=True, separator=';')\n","        tensorboard = TensorBoard(log_dir='./tensorboard_unet/', write_graph=True, write_images=True)\n","        model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n","                  verbose=2, shuffle=True,\n","                  callbacks=[model_checkpoint, csv_logger, tensorboard],\n","                  validation_data=(x_val, y_val))\n","        return model\n","\n","model = train_net()\n","model.save('/content/drive/My Drive/Colab Notebooks/satelliteimage_segmentation/satellite_model.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading images\n","01 read\n","02 read\n","03 read\n","04 read\n","05 read\n","06 read\n","07 read\n","08 read\n","09 read\n","10 read\n","11 read\n","12 read\n","13 read\n","14 read\n","15 read\n","16 read\n","17 read\n","18 read\n","19 read\n","20 read\n","21 read\n","22 read\n","23 read\n","24 read\n","Images were read\n","start train net\n","Generated 4000 patches\n","Generated 1000 patches\n","Train on 4000 samples, validate on 1000 samples\n","Epoch 1/150\n"],"name":"stdout"}]}]}